{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c887076d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asami\\AppData\\Local\\Temp\\ipykernel_3540\\2687732498.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_anim[\"time_3h\"] = df_anim[\"time_jst\"].dt.floor(\"3H\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "# CSV読み込み\n",
    "df = pd.read_csv(\"earthquakes.csv\")\n",
    "\n",
    "# 日本時間へ変換\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "df[\"time_jst\"] = df[\"time\"] + pd.Timedelta(hours=9)\n",
    "\n",
    "# 3時間ごとに丸める\n",
    "df_anim = df.copy()\n",
    "df_anim[\"time_3h\"] = df_anim[\"time_jst\"].dt.floor(\"3H\")\n",
    "df_anim[\"time_str\"] = df_anim[\"time_3h\"].dt.strftime(\"%Y-%m-%d %H:00\")\n",
    "\n",
    "# 深さで色分け\n",
    "conditions = [\n",
    "    (df_anim[\"depth\"] <= 70),\n",
    "    (df_anim[\"depth\"] > 70) & (df_anim[\"depth\"] <= 300),\n",
    "    (df_anim[\"depth\"] > 300)\n",
    "]\n",
    "\n",
    "colors = [\"green\", \"orange\", \"blue\"]  # 浅・中・深\n",
    "\n",
    "df_anim[\"depth_color\"] = np.select(conditions, colors, default=\"gray\")\n",
    "\n",
    "# マグニチュードでサイズ\n",
    "df_anim[\"size\"] = df_anim[\"mag\"] ** 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3c4dd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>...</th>\n",
       "      <th>updated</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-19T02:14:34.839Z</td>\n",
       "      <td>59.385216</td>\n",
       "      <td>-138.712936</td>\n",
       "      <td>5.815022</td>\n",
       "      <td>2.769645</td>\n",
       "      <td>ml</td>\n",
       "      <td>15.0</td>\n",
       "      <td>186.461739</td>\n",
       "      <td>0.450602</td>\n",
       "      <td>0.807060</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-11-19T02:16:45.431Z</td>\n",
       "      <td>60 km ESE of Yakutat, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.748861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-19T02:08:16.932Z</td>\n",
       "      <td>62.943947</td>\n",
       "      <td>-150.472092</td>\n",
       "      <td>103.293152</td>\n",
       "      <td>2.039515</td>\n",
       "      <td>ml</td>\n",
       "      <td>25.0</td>\n",
       "      <td>45.500549</td>\n",
       "      <td>0.441669</td>\n",
       "      <td>0.488629</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-11-19T02:09:41.617Z</td>\n",
       "      <td>52 km NNE of Petersville, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.418342</td>\n",
       "      <td>0.479709</td>\n",
       "      <td>2.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-19T01:52:37.540Z</td>\n",
       "      <td>37.762333</td>\n",
       "      <td>-121.943001</td>\n",
       "      <td>6.170000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>md</td>\n",
       "      <td>14.0</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>0.025990</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-11-19T02:17:18.670Z</td>\n",
       "      <td>4 km ESE of San Ramon, CA</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-19T01:48:36.220Z</td>\n",
       "      <td>37.286167</td>\n",
       "      <td>-121.658501</td>\n",
       "      <td>5.660000</td>\n",
       "      <td>2.960000</td>\n",
       "      <td>md</td>\n",
       "      <td>89.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.029530</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-11-19T02:30:16.668Z</td>\n",
       "      <td>16 km E of Seven Trees, CA</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>132.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-19T01:38:54.976Z</td>\n",
       "      <td>31.658000</td>\n",
       "      <td>-104.322000</td>\n",
       "      <td>7.150900</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>ml</td>\n",
       "      <td>31.0</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-11-19T02:17:10.155Z</td>\n",
       "      <td>57 km S of Whites City, New Mexico</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.622503</td>\n",
       "      <td>0.725843</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>tx</td>\n",
       "      <td>tx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time   latitude   longitude       depth       mag  \\\n",
       "0  2025-11-19T02:14:34.839Z  59.385216 -138.712936    5.815022  2.769645   \n",
       "1  2025-11-19T02:08:16.932Z  62.943947 -150.472092  103.293152  2.039515   \n",
       "2  2025-11-19T01:52:37.540Z  37.762333 -121.943001    6.170000  1.790000   \n",
       "3  2025-11-19T01:48:36.220Z  37.286167 -121.658501    5.660000  2.960000   \n",
       "4  2025-11-19T01:38:54.976Z  31.658000 -104.322000    7.150900  1.700000   \n",
       "\n",
       "  magType   nst         gap      dmin       rms  ...  \\\n",
       "0      ml  15.0  186.461739  0.450602  0.807060  ...   \n",
       "1      ml  25.0   45.500549  0.441669  0.488629  ...   \n",
       "2      md  14.0   94.000000  0.025990  0.110000  ...   \n",
       "3      md  89.0   41.000000  0.029530  0.070000  ...   \n",
       "4      ml  31.0   68.000000  0.100000  0.100000  ...   \n",
       "\n",
       "                    updated                               place        type  \\\n",
       "0  2025-11-19T02:16:45.431Z        60 km ESE of Yakutat, Alaska  earthquake   \n",
       "1  2025-11-19T02:09:41.617Z    52 km NNE of Petersville, Alaska  earthquake   \n",
       "2  2025-11-19T02:17:18.670Z           4 km ESE of San Ramon, CA  earthquake   \n",
       "3  2025-11-19T02:30:16.668Z          16 km E of Seven Trees, CA  earthquake   \n",
       "4  2025-11-19T02:17:10.155Z  57 km S of Whites City, New Mexico  earthquake   \n",
       "\n",
       "  horizontalError depthError  magError  magNst     status  locationSource  \\\n",
       "0        0.000000   2.748861  0.000000     1.0  automatic              ak   \n",
       "1        0.000000   3.418342  0.479709     2.0  automatic              ak   \n",
       "2        0.340000   0.660000  0.120000    12.0  automatic              nc   \n",
       "3        0.110000   0.230000  0.150000   132.0  automatic              nc   \n",
       "4        0.622503   0.725843  0.100000    18.0   reviewed              tx   \n",
       "\n",
       "  magSource  \n",
       "0        ak  \n",
       "1        ak  \n",
       "2        nc  \n",
       "3        nc  \n",
       "4        tx  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# USGSから過去1か月の地震データを取得\n",
    "url = \"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.csv\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# データをファイルに保存\n",
    "with open('earthquakes.csv', 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "# データをDataFrameに読み込む\n",
    "data = pd.read_csv('earthquakes.csv')\n",
    "\n",
    "# データの最初の5行を表示\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "693a5e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: requests in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: plotly in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (6.5.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asami\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from plotly) (2.12.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\asami\\appdata\\roaming\\python\\python313\\site-packages (from plotly) (25.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asami\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Jupyter 上で実行\n",
    "!pip install pandas requests plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8b983bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asami\\AppData\\Local\\Temp\\ipykernel_3540\\101846607.py:9: DeprecationWarning:\n",
      "\n",
      "datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting monthly USGS data...\n",
      " → 2024-11-01 ～ 2024-12-01\n",
      " → 2024-12-01 ～ 2025-01-01\n",
      " → 2025-01-01 ～ 2025-02-01\n",
      " → 2025-02-01 ～ 2025-03-01\n",
      " → 2025-03-01 ～ 2025-04-01\n",
      " → 2025-04-01 ～ 2025-05-01\n",
      " → 2025-05-01 ～ 2025-06-01\n",
      " → 2025-06-01 ～ 2025-07-01\n",
      " → 2025-07-01 ～ 2025-08-01\n",
      " → 2025-08-01 ～ 2025-09-01\n",
      " → 2025-09-01 ～ 2025-10-01\n",
      " → 2025-10-01 ～ 2025-11-01\n",
      " → 2025-11-01 ～ 2025-11-19\n",
      "\n",
      "DONE! 総イベント数: 29291 件\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>...</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "      <th>time_jst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-30T23:52:45.796Z</td>\n",
       "      <td>-7.657000</td>\n",
       "      <td>127.755500</td>\n",
       "      <td>168.706</td>\n",
       "      <td>4.20</td>\n",
       "      <td>mb</td>\n",
       "      <td>19.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3.777000</td>\n",
       "      <td>0.93</td>\n",
       "      <td>...</td>\n",
       "      <td>126 km NE of Lospalos, Timor Leste</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>8.64</td>\n",
       "      <td>8.252</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-12-01 08:52:45.796000+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-30T23:19:38.580Z</td>\n",
       "      <td>19.386167</td>\n",
       "      <td>-155.242833</td>\n",
       "      <td>1.960</td>\n",
       "      <td>3.08</td>\n",
       "      <td>ml</td>\n",
       "      <td>28.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.008029</td>\n",
       "      <td>0.11</td>\n",
       "      <td>...</td>\n",
       "      <td>6 km S of Volcano, Hawaii</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.397188</td>\n",
       "      <td>22.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>hv</td>\n",
       "      <td>hv</td>\n",
       "      <td>2024-12-01 08:19:38.580000+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-30T23:18:42.830Z</td>\n",
       "      <td>19.387667</td>\n",
       "      <td>-155.242833</td>\n",
       "      <td>1.810</td>\n",
       "      <td>2.50</td>\n",
       "      <td>ml</td>\n",
       "      <td>49.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.008285</td>\n",
       "      <td>0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>6 km S of Volcano, Hawaii</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.262802</td>\n",
       "      <td>32.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>hv</td>\n",
       "      <td>hv</td>\n",
       "      <td>2024-12-01 08:18:42.830000+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-30T22:12:26.968Z</td>\n",
       "      <td>-22.581700</td>\n",
       "      <td>-12.956900</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.80</td>\n",
       "      <td>mb</td>\n",
       "      <td>42.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>26.676000</td>\n",
       "      <td>1.01</td>\n",
       "      <td>...</td>\n",
       "      <td>southern Mid-Atlantic Ridge</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>12.03</td>\n",
       "      <td>1.884</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-12-01 07:12:26.968000+09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-30T21:36:05.908Z</td>\n",
       "      <td>13.054300</td>\n",
       "      <td>143.926400</td>\n",
       "      <td>132.912</td>\n",
       "      <td>4.70</td>\n",
       "      <td>mb</td>\n",
       "      <td>150.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.060000</td>\n",
       "      <td>0.66</td>\n",
       "      <td>...</td>\n",
       "      <td>83 km WSW of Merizo Village, Guam</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>9.23</td>\n",
       "      <td>5.913</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>129.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-12-01 06:36:05.908000+09:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time   latitude   longitude    depth   mag magType  \\\n",
       "0  2024-11-30T23:52:45.796Z  -7.657000  127.755500  168.706  4.20      mb   \n",
       "1  2024-11-30T23:19:38.580Z  19.386167 -155.242833    1.960  3.08      ml   \n",
       "2  2024-11-30T23:18:42.830Z  19.387667 -155.242833    1.810  2.50      ml   \n",
       "3  2024-11-30T22:12:26.968Z -22.581700  -12.956900   10.000  4.80      mb   \n",
       "4  2024-11-30T21:36:05.908Z  13.054300  143.926400  132.912  4.70      mb   \n",
       "\n",
       "     nst   gap       dmin   rms  ...                               place  \\\n",
       "0   19.0  91.0   3.777000  0.93  ...  126 km NE of Lospalos, Timor Leste   \n",
       "1   28.0  67.0   0.008029  0.11  ...           6 km S of Volcano, Hawaii   \n",
       "2   49.0  52.0   0.008285  0.10  ...           6 km S of Volcano, Hawaii   \n",
       "3   42.0  50.0  26.676000  1.01  ...         southern Mid-Atlantic Ridge   \n",
       "4  150.0  40.0   1.060000  0.66  ...   83 km WSW of Merizo Village, Guam   \n",
       "\n",
       "         type horizontalError depthError  magError  magNst    status  \\\n",
       "0  earthquake            8.64      8.252  0.132000    16.0  reviewed   \n",
       "1  earthquake            0.17      0.150  0.397188    22.0  reviewed   \n",
       "2  earthquake            0.19      0.180  0.262802    32.0  reviewed   \n",
       "3  earthquake           12.03      1.884  0.089000    39.0  reviewed   \n",
       "4  earthquake            9.23      5.913  0.049000   129.0  reviewed   \n",
       "\n",
       "   locationSource  magSource                         time_jst  \n",
       "0              us         us 2024-12-01 08:52:45.796000+09:00  \n",
       "1              hv         hv 2024-12-01 08:19:38.580000+09:00  \n",
       "2              hv         hv 2024-12-01 08:18:42.830000+09:00  \n",
       "3              us         us 2024-12-01 07:12:26.968000+09:00  \n",
       "4              us         us 2024-12-01 06:36:05.908000+09:00  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ------------------\n",
    "# 期間を設定（過去1年）\n",
    "# ------------------\n",
    "end = datetime.utcnow()\n",
    "start = end - timedelta(days=365)\n",
    "\n",
    "# 月ごとに分割\n",
    "def month_ranges(start, end):\n",
    "    ranges = []\n",
    "    cur = start.replace(day=1)\n",
    "    while cur < end:\n",
    "        if cur.month == 12:\n",
    "            nxt = cur.replace(year=cur.year+1, month=1, day=1)\n",
    "        else:\n",
    "            nxt = cur.replace(month=cur.month+1, day=1)\n",
    "        ranges.append((cur, min(nxt, end)))\n",
    "        cur = nxt\n",
    "    return ranges\n",
    "\n",
    "ranges = month_ranges(start, end)\n",
    "\n",
    "# ------------------\n",
    "# USGS API\n",
    "# ------------------\n",
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "\n",
    "all_df = []\n",
    "\n",
    "print(\"Requesting monthly USGS data...\")\n",
    "\n",
    "for s, e in ranges:\n",
    "    params = {\n",
    "        \"format\": \"csv\",\n",
    "        \"starttime\": s.strftime(\"%Y-%m-%d\"),\n",
    "        \"endtime\": e.strftime(\"%Y-%m-%d\"),\n",
    "        \"minmagnitude\": 2.5,\n",
    "        \"orderby\": \"time\"\n",
    "    }\n",
    "    print(f\" → {params['starttime']} ～ {params['endtime']}\")\n",
    "\n",
    "    resp = requests.get(url, params=params)\n",
    "    resp.raise_for_status()  # ← 500 が出たらここで止まる\n",
    "\n",
    "    df = pd.read_csv(StringIO(resp.text))\n",
    "    all_df.append(df)\n",
    "\n",
    "# ------------------\n",
    "# データを結合\n",
    "# ------------------\n",
    "df_all = pd.concat(all_df, ignore_index=True)\n",
    "\n",
    "print(f\"\\nDONE! 総イベント数: {len(df_all)} 件\")\n",
    "\n",
    "# ------------------\n",
    "# 日本時間（JST）に変換\n",
    "# ------------------\n",
    "df_all[\"time_jst\"] = pd.to_datetime(df_all[\"time\"], utc=True).dt.tz_convert(\"Asia/Tokyo\")\n",
    "\n",
    "df_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8bc73bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting USGS data ...\n",
      "Raw events fetched: 247\n",
      "Saved to query.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# ======================================\n",
    "# ① 取得期間を設定（過去7日間）\n",
    "# ======================================\n",
    "end_time = datetime.now(timezone.utc)\n",
    "start_time = end_time - timedelta(days=7)\n",
    "\n",
    "# USGS API\n",
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "params = {\n",
    "    \"format\": \"csv\",\n",
    "    \"starttime\": start_time.strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "    \"endtime\": end_time.strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "    \"minmagnitude\": 2.5\n",
    "}\n",
    "\n",
    "print(\"Requesting USGS data ...\")\n",
    "resp = requests.get(url, params=params)\n",
    "resp.raise_for_status()\n",
    "\n",
    "# CSV を pandas に読み込む\n",
    "df = pd.read_csv(StringIO(resp.text))\n",
    "print(f\"Raw events fetched: {len(df)}\")\n",
    "\n",
    "# query.csv に保存\n",
    "df.to_csv(\"query.csv\", index=False)\n",
    "print(\"Saved to query.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "889ca48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded: (247, 22)\n",
      "                       time                         time_jst   latitude  \\\n",
      "0  2025-11-19T02:45:00.925Z 2025-11-19 11:45:00.925000+09:00  55.460300   \n",
      "1  2025-11-19T02:23:19.189Z 2025-11-19 11:23:19.189000+09:00  39.235200   \n",
      "2  2025-11-19T02:14:34.839Z 2025-11-19 11:14:34.839000+09:00  59.385216   \n",
      "3  2025-11-19T01:48:36.220Z 2025-11-19 10:48:36.220000+09:00  37.286167   \n",
      "4  2025-11-19T01:38:53.994Z 2025-11-19 10:38:53.994000+09:00  10.870900   \n",
      "\n",
      "    longitude       mag  \n",
      "0 -157.214157  2.547544  \n",
      "1  143.467800  5.000000  \n",
      "2 -138.712936  2.769645  \n",
      "3 -121.658501  2.960000  \n",
      "4  -62.756600  5.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# query.csv を読み込み\n",
    "df = pd.read_csv(\"query.csv\")\n",
    "print(\"CSV loaded:\", df.shape)\n",
    "\n",
    "# UTC → JST に変換\n",
    "df[\"time_jst\"] = (\n",
    "    pd.to_datetime(df[\"time\"], utc=True)\n",
    "      .dt.tz_convert(\"Asia/Tokyo\")\n",
    ")\n",
    "\n",
    "print(df[[\"time\", \"time_jst\", \"latitude\", \"longitude\", \"mag\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "03bac20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: plotly in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (6.5.0)\n",
      "Requirement already satisfied: requests in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asami\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from plotly) (2.12.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\asami\\appdata\\roaming\\python\\python313\\site-packages (from plotly) (25.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asami\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asami\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas plotly requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a236d514",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Timestamp is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[117]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m records = df.to_dict(orient=\u001b[33m\"\u001b[39m\u001b[33mrecords\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mearthquake_data.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexpress\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpx\u001b[39;00m\n\u001b[32m     28\u001b[39m fig = px.scatter_geo(\n\u001b[32m     29\u001b[39m     df,\n\u001b[32m     30\u001b[39m     lon=\u001b[33m\"\u001b[39m\u001b[33mlongitude\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m     title=\u001b[33m\"\u001b[39m\u001b[33m過去30日間の地震アニメーション（JST）\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     38\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\__init__.py:179\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    173\u001b[39m     iterable = \u001b[38;5;28mcls\u001b[39m(skipkeys=skipkeys, ensure_ascii=ensure_ascii,\n\u001b[32m    174\u001b[39m         check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n\u001b[32m    175\u001b[39m         separators=separators,\n\u001b[32m    176\u001b[39m         default=default, sort_keys=sort_keys, **kw).iterencode(obj)\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\encoder.py:431\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    429\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m _floatstr(o)\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    433\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\encoder.py:326\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode_list\u001b[39m\u001b[34m(lst, _current_indent_level)\u001b[39m\n\u001b[32m    324\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    325\u001b[39m             chunks = _iterencode(value, _current_indent_level)\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    328\u001b[39m     _current_indent_level -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\encoder.py:407\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode_dict\u001b[39m\u001b[34m(dct, _current_indent_level)\u001b[39m\n\u001b[32m    405\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    406\u001b[39m             chunks = _iterencode(value, _current_indent_level)\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m first \u001b[38;5;129;01mand\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    409\u001b[39m     _current_indent_level -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\encoder.py:440\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    438\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCircular reference detected\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    439\u001b[39m     markers[markerid] = o\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m o = \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type Timestamp is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 深さカテゴリ\n",
    "conditions = [\n",
    "    (df[\"depth\"] < 10),\n",
    "    (df[\"depth\"] >= 10) & (df[\"depth\"] < 50),\n",
    "    (df[\"depth\"] >= 50)\n",
    "]\n",
    "\n",
    "choices = [\"浅い(Shallow)\", \"中間(Middle)\", \"深い(Deep)\"]\n",
    "\n",
    "df[\"depth_category\"] = np.select(\n",
    "    conditions,\n",
    "    choices,\n",
    "    default=\"不明(Unknown)\"\n",
    ")\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "records = df.to_dict(orient=\"records\")\n",
    "\n",
    "with open(\"earthquake_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(records, f, ensure_ascii=False)\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_geo(\n",
    "    df,\n",
    "    lon=\"longitude\",\n",
    "    lat=\"latitude\",\n",
    "    color=\"depth_category\",\n",
    "    size=\"mag\",\n",
    "    animation_frame=\"date_jst\",\n",
    "    hover_name=\"time_jst\",\n",
    "    projection=\"natural earth\",\n",
    "    title=\"過去30日間の地震アニメーション（JST）\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    legend_title=\"深さカテゴリ\",\n",
    "    geo=dict(\n",
    "        showland=True,\n",
    "        landcolor=\"rgb(229, 229, 229)\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8ea9dbfb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date_jst'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'date_jst'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[118]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m      6\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mtime_jst\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mtime_jst\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mdate_jst\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdate_jst\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.astype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# ② numpy 型 → Python ネイティブ型に変換\u001b[39;00m\n\u001b[32m     10\u001b[39m df = df.astype({\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlatitude\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlongitude\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdepth\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmag\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m\n\u001b[32m     15\u001b[39m })\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'date_jst'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# ① JST を文字列化（datetime は JSON にできない）\n",
    "df[\"time\"] = df[\"time\"].astype(str)\n",
    "df[\"time_jst\"] = df[\"time_jst\"].astype(str)\n",
    "df[\"date_jst\"] = df[\"date_jst\"].astype(str)\n",
    "\n",
    "# ② numpy 型 → Python ネイティブ型に変換\n",
    "df = df.astype({\n",
    "    \"latitude\": float,\n",
    "    \"longitude\": float,\n",
    "    \"depth\": float,\n",
    "    \"mag\": float\n",
    "})\n",
    "\n",
    "# カテゴリも文字列確定\n",
    "df[\"depth_category\"] = df[\"depth_category\"].astype(str)\n",
    "\n",
    "# ③ 辞書化 → JSON 書き出し\n",
    "records = df.to_dict(orient=\"records\")\n",
    "\n",
    "with open(\"earthquake_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(records, f, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "55ab0e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded: (247, 22)\n",
      "                       time                         time_jst    date_jst  \\\n",
      "0  2025-11-19T02:45:00.925Z 2025-11-19 11:45:00.925000+09:00  2025-11-19   \n",
      "1  2025-11-19T02:23:19.189Z 2025-11-19 11:23:19.189000+09:00  2025-11-19   \n",
      "2  2025-11-19T02:14:34.839Z 2025-11-19 11:14:34.839000+09:00  2025-11-19   \n",
      "3  2025-11-19T01:48:36.220Z 2025-11-19 10:48:36.220000+09:00  2025-11-19   \n",
      "4  2025-11-19T01:38:53.994Z 2025-11-19 10:38:53.994000+09:00  2025-11-19   \n",
      "\n",
      "    latitude   longitude       mag  \n",
      "0  55.460300 -157.214157  2.547544  \n",
      "1  39.235200  143.467800  5.000000  \n",
      "2  59.385216 -138.712936  2.769645  \n",
      "3  37.286167 -121.658501  2.960000  \n",
      "4  10.870900  -62.756600  5.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV を読み込み\n",
    "df = pd.read_csv(\"query.csv\")\n",
    "print(\"CSV loaded:\", df.shape)\n",
    "\n",
    "# UTC → JST に変換\n",
    "df[\"time_jst\"] = (\n",
    "    pd.to_datetime(df[\"time\"], utc=True)\n",
    "      .dt.tz_convert(\"Asia/Tokyo\")\n",
    ")\n",
    "\n",
    "# ← これが必要！\n",
    "df[\"date_jst\"] = df[\"time_jst\"].dt.date\n",
    "\n",
    "print(df[[\"time\", \"time_jst\", \"date_jst\", \"latitude\", \"longitude\", \"mag\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2eb118e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 地図を保存しました → earthquakes_map.html\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# 地図の中心（適当に日本周辺に設定、必要あれば変更）\n",
    "m = folium.Map(location=[35, 140], zoom_start=3)\n",
    "\n",
    "# MarkerCluster（点が多いのでまとめる）\n",
    "cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "# 地震をマップに表示\n",
    "for _, row in df.iterrows():\n",
    "    lat = row[\"latitude\"]\n",
    "    lon = row[\"longitude\"]\n",
    "    mag = row[\"mag\"]\n",
    "    time = row[\"time_jst\"]\n",
    "\n",
    "    folium.CircleMarker(\n",
    "        location=[lat, lon],\n",
    "        radius=max(mag, 1),  # マグニチュードで大きさ変える\n",
    "        color=\"red\",\n",
    "        fill=True,\n",
    "        fill_opacity=0.7,\n",
    "        popup=f\"M {mag}<br>{time}\"\n",
    "    ).add_to(cluster)\n",
    "\n",
    "# HTMLに保存\n",
    "m.save(\"earthquakes_map.html\")\n",
    "print(\"✔ 地図を保存しました → earthquakes_map.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6ca127ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 地図ファイル作成: earthquakes_map.html\n",
      "🌏 自動でブラウザを開きました\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import webbrowser\n",
    "import os\n",
    "\n",
    "# 地図の中心\n",
    "m = folium.Map(location=[35, 140], zoom_start=3)\n",
    "\n",
    "# マーカーをまとめる\n",
    "cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "# 地震をマップに表示\n",
    "for _, row in df.iterrows():\n",
    "    lat = row[\"latitude\"]\n",
    "    lon = row[\"longitude\"]\n",
    "    mag = row[\"mag\"]\n",
    "    time = row[\"time_jst\"]\n",
    "\n",
    "    folium.CircleMarker(\n",
    "        location=[lat, lon],\n",
    "        radius=max(mag, 1),\n",
    "        color=\"red\",\n",
    "        fill=True,\n",
    "        fill_opacity=0.7,\n",
    "        popup=f\"M {mag}<br>{time}\"\n",
    "    ).add_to(cluster)\n",
    "\n",
    "# 保存\n",
    "filename = \"earthquakes_map.html\"\n",
    "m.save(filename)\n",
    "print(\"✔ 地図ファイル作成:\", filename)\n",
    "\n",
    "# ブラウザで自動オープン\n",
    "fullpath = os.path.abspath(filename)\n",
    "webbrowser.open(f\"file://{fullpath}\")\n",
    "print(\"🌏 自動でブラウザを開きました\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "057b01ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'time'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[138]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      8\u001b[39m df = pd.read_csv(url)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 2) UTC → JST\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     13\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mtime_jst\u001b[39m\u001b[33m\"\u001b[39m] = (\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     pd.to_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, utc=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     15\u001b[39m       .dt.tz_convert(\u001b[33m\"\u001b[39m\u001b[33mAsia/Tokyo\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# 3) 3時間ごとに丸める\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     21\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mtime_bin\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mtime_jst\u001b[39m\u001b[33m\"\u001b[39m].dt.floor(\u001b[33m\"\u001b[39m\u001b[33m3H\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'time'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# -----------------------------\n",
    "# 1) データ読み込み（USGS 過去1年）\n",
    "# -----------------------------\n",
    "url = \"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_year.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) UTC → JST\n",
    "# -----------------------------\n",
    "df[\"time_jst\"] = (\n",
    "    pd.to_datetime(df[\"time\"], utc=True)\n",
    "      .dt.tz_convert(\"Asia/Tokyo\")\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) 3時間ごとに丸める\n",
    "# -----------------------------\n",
    "df[\"time_bin\"] = df[\"time_jst\"].dt.floor(\"3H\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Plotly アニメーション地図\n",
    "# -----------------------------\n",
    "fig = px.scatter_geo(\n",
    "    df,\n",
    "    lat=\"latitude\",\n",
    "    lon=\"longitude\",\n",
    "    color=\"mag\",\n",
    "    size=\"mag\",\n",
    "    hover_name=\"place\",\n",
    "    animation_frame=\"time_bin\",\n",
    "    projection=\"natural earth\",\n",
    "    color_continuous_scale=\"Turbo\",\n",
    "    range_color=(0, df[\"mag\"].max()),\n",
    "    title=\"🌏 過去1年間の地震（3時間ごとのアニメーション, JST）\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    height=700,\n",
    "    geo=dict(\n",
    "        showland=True,\n",
    "        landcolor=\"rgb(230,230,230)\",\n",
    "        showocean=True,\n",
    "        oceancolor=\"rgb(200,220,255)\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "46bdd0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['404 File Not Found']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_year.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "67d3529e",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 400: Bad Request",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[140]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      5\u001b[39m start = end - pd.Timedelta(days=\u001b[32m365\u001b[39m)\n\u001b[32m      7\u001b[39m url = (\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhttps://earthquake.usgs.gov/fdsnws/event/1/query\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m?format=csv&starttime=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart.strftime(\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m&endtime=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend.strftime(\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoaded:\u001b[39m\u001b[33m\"\u001b[39m, df.shape)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# ▼ UTC → JST\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:728\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    725\u001b[39m     codecs.lookup_error(errors)\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m ioargs = \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m handle = ioargs.filepath_or_buffer\n\u001b[32m    737\u001b[39m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:384\u001b[39m, in \u001b[36m_get_filepath_or_buffer\u001b[39m\u001b[34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[32m    383\u001b[39m req_info = urllib.request.Request(filepath_or_buffer, headers=storage_options)\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[32m    385\u001b[39m     content_encoding = req.headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Encoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding == \u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:289\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[33;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03mthe stdlib.\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrequest\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py:189\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, context)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    188\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py:495\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    494\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py:604\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    601\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    602\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py:533\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    532\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py:466\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    465\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    468\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asami\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\urllib\\request.py:613\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 400: Bad Request"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ▼ 1年間のデータ取得（今日基準）\n",
    "end = pd.Timestamp.utcnow()\n",
    "start = end - pd.Timedelta(days=365)\n",
    "\n",
    "url = (\n",
    "    \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "    f\"?format=csv&starttime={start.strftime('%Y-%m-%d')}\"\n",
    "    f\"&endtime={end.strftime('%Y-%m-%d')}\"\n",
    ")\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "print(\"Loaded:\", df.shape)\n",
    "\n",
    "# ▼ UTC → JST\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"], utc=True)\n",
    "df[\"time_jst\"] = df[\"time\"].dt.tz_convert(\"Asia/Tokyo\")\n",
    "df[\"date_jst\"] = df[\"time_jst\"].dt.floor(\"3h\")   # 3時間ごとに丸める\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "30be0c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asami\\AppData\\Local\\Temp\\ipykernel_3540\\2411888538.py:4: DeprecationWarning:\n",
      "\n",
      "datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2024-11-19&endtime=2025-11-19&orderby=time&limit=20000\n",
      "Loaded: (20000, 22)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "end = dt.datetime.utcnow()\n",
    "start = end - dt.timedelta(days=365)\n",
    "\n",
    "url = (\n",
    "    \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "    f\"?format=csv\"\n",
    "    f\"&starttime={start.strftime('%Y-%m-%d')}\"\n",
    "    f\"&endtime={end.strftime('%Y-%m-%d')}\"\n",
    "    f\"&orderby=time\"\n",
    "    f\"&limit=20000\"\n",
    ")\n",
    "\n",
    "print(url)\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "print(\"Loaded:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fa885a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asami\\AppData\\Local\\Temp\\ipykernel_3540\\2344315134.py:19: DeprecationWarning:\n",
      "\n",
      "datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2024-11-19&endtime=2024-12-01&limit=20000&orderby=time\n",
      "  → 4284 rows\n",
      "Downloading: https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2024-12-01&endtime=2025-01-01&limit=20000&orderby=time\n",
      "  → 13050 rows\n",
      "Downloading: https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2025-01-01&endtime=2025-02-01&limit=20000&orderby=time\n",
      "  → 11642 rows\n",
      "Downloading: https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2025-02-01&endtime=2025-03-01&limit=20000&orderby=time\n",
      "  → 11489 rows\n",
      "Downloading: https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2025-03-01&endtime=2025-04-01&limit=20000&orderby=time\n",
      "  → 11863 rows\n",
      "Downloading: https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2025-04-01&endtime=2025-05-01&limit=20000&orderby=time\n",
      "  → 11234 rows\n",
      "Downloading: https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2025-05-01&endtime=2025-06-01&limit=20000&orderby=time\n",
      "  → 10384 rows\n",
      "Downloading: https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2025-06-01&endtime=2025-07-01&limit=20000&orderby=time\n",
      "  → 10595 rows\n",
      "Downloading: https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2025-07-01&endtime=2025-08-01&limit=20000&orderby=time\n",
      "  → 16456 rows\n",
      "Downloading: https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2025-08-01&endtime=2025-09-01&limit=20000&orderby=time\n",
      "  → 12584 rows\n",
      "Downloading: https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2025-09-01&endtime=2025-10-01&limit=20000&orderby=time\n",
      "  → 11166 rows\n",
      "Downloading: https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2025-10-01&endtime=2025-11-01&limit=20000&orderby=time\n",
      "  → 8756 rows\n",
      "Downloading: https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv&starttime=2025-11-01&endtime=2025-11-19&limit=20000&orderby=time\n",
      "  → 4642 rows\n",
      "\n",
      "=== DONE ===\n",
      "Total rows: 138145\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_jst</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>...</th>\n",
       "      <th>updated</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-01 08:54:01.872000+00:00</td>\n",
       "      <td>56.217500</td>\n",
       "      <td>-157.973100</td>\n",
       "      <td>61.800</td>\n",
       "      <td>1.90</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.40</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-01-07T21:33:55.459Z</td>\n",
       "      <td>28 km ESE of Chignik, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>ak</td>\n",
       "      <td>ak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-01 08:52:45.796000+00:00</td>\n",
       "      <td>-7.657000</td>\n",
       "      <td>127.755500</td>\n",
       "      <td>168.706</td>\n",
       "      <td>4.20</td>\n",
       "      <td>mb</td>\n",
       "      <td>19.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3.777000</td>\n",
       "      <td>0.93</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-02-02T00:54:22.040Z</td>\n",
       "      <td>126 km NE of Lospalos, Timor Leste</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>8.64</td>\n",
       "      <td>8.252</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-01 08:52:23.360000+00:00</td>\n",
       "      <td>38.825001</td>\n",
       "      <td>-122.801498</td>\n",
       "      <td>3.010</td>\n",
       "      <td>0.71</td>\n",
       "      <td>md</td>\n",
       "      <td>11.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.006888</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-01T00:17:18.431Z</td>\n",
       "      <td>7 km NNW of The Geysers, CA</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>nc</td>\n",
       "      <td>nc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-01 08:49:23.160000+00:00</td>\n",
       "      <td>35.536833</td>\n",
       "      <td>-96.754000</td>\n",
       "      <td>5.560</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>ml</td>\n",
       "      <td>8.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.013497</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-03T18:39:49.346Z</td>\n",
       "      <td>8 km NW of Prague, Oklahoma</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>ok</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-01 08:46:06.360000+00:00</td>\n",
       "      <td>60.659667</td>\n",
       "      <td>-152.569667</td>\n",
       "      <td>22.400</td>\n",
       "      <td>1.11</td>\n",
       "      <td>ml</td>\n",
       "      <td>3.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>0.182100</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>2024-12-04T20:05:20.540Z</td>\n",
       "      <td>68 km W of Salamatof, Alaska</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>3.12</td>\n",
       "      <td>3.090</td>\n",
       "      <td>0.356026</td>\n",
       "      <td>4.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>av</td>\n",
       "      <td>av</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          time_jst   latitude   longitude    depth   mag  \\\n",
       "0 2024-12-01 08:54:01.872000+00:00  56.217500 -157.973100   61.800  1.90   \n",
       "1 2024-12-01 08:52:45.796000+00:00  -7.657000  127.755500  168.706  4.20   \n",
       "2 2024-12-01 08:52:23.360000+00:00  38.825001 -122.801498    3.010  0.71   \n",
       "3 2024-12-01 08:49:23.160000+00:00  35.536833  -96.754000    5.560 -1.94   \n",
       "4 2024-12-01 08:46:06.360000+00:00  60.659667 -152.569667   22.400  1.11   \n",
       "\n",
       "  magType   nst    gap      dmin   rms  ...                   updated  \\\n",
       "0      ml   NaN    NaN       NaN  0.40  ...  2025-01-07T21:33:55.459Z   \n",
       "1      mb  19.0   91.0  3.777000  0.93  ...  2025-02-02T00:54:22.040Z   \n",
       "2      md  11.0   71.0  0.006888  0.05  ...  2024-12-01T00:17:18.431Z   \n",
       "3      ml   8.0  140.0  0.013497  0.01  ...  2024-12-03T18:39:49.346Z   \n",
       "4      ml   3.0  341.0  0.182100  0.06  ...  2024-12-04T20:05:20.540Z   \n",
       "\n",
       "                                place        type horizontalError depthError  \\\n",
       "0        28 km ESE of Chignik, Alaska  earthquake             NaN      0.400   \n",
       "1  126 km NE of Lospalos, Timor Leste  earthquake            8.64      8.252   \n",
       "2         7 km NNW of The Geysers, CA  earthquake            0.48      0.830   \n",
       "3         8 km NW of Prague, Oklahoma  earthquake             NaN      0.100   \n",
       "4        68 km W of Salamatof, Alaska  earthquake            3.12      3.090   \n",
       "\n",
       "   magError  magNst     status  locationSource magSource  \n",
       "0       NaN     NaN   reviewed              ak        ak  \n",
       "1  0.132000    16.0   reviewed              us        us  \n",
       "2  0.280000    12.0  automatic              nc        nc  \n",
       "3  0.000000     1.0   reviewed              ok        ok  \n",
       "4  0.356026     4.0   reviewed              av        av  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "def fetch_usgs_month(start, end):\n",
    "    \"\"\"1ヶ月分の USGS 地震データ(最大20万件) を CSV で取得\"\"\"\n",
    "    url = (\n",
    "        \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "        f\"?format=csv\"\n",
    "        f\"&starttime={start.strftime('%Y-%m-%d')}\"\n",
    "        f\"&endtime={end.strftime('%Y-%m-%d')}\"\n",
    "        f\"&limit=20000\"\n",
    "        f\"&orderby=time\"\n",
    "    )\n",
    "    print(\"Downloading:\", url)\n",
    "    return pd.read_csv(url)\n",
    "\n",
    "\n",
    "# ▼ 過去1年の区間を月ごとに分割して取得\n",
    "end = dt.datetime.utcnow()\n",
    "start = end - dt.timedelta(days=365)\n",
    "\n",
    "dfs = []\n",
    "cur = start\n",
    "\n",
    "while cur < end:\n",
    "    # 月末の計算\n",
    "    next_month = (cur.replace(day=28) + dt.timedelta(days=4)).replace(day=1)\n",
    "    month_end = min(next_month, end)\n",
    "\n",
    "    try:\n",
    "        df_month = fetch_usgs_month(cur, month_end)\n",
    "        dfs.append(df_month)\n",
    "        print(f\"  → {len(df_month)} rows\")\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "    cur = month_end  # 次の月へ\n",
    "\n",
    "# ▼ 全部結合\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "print(\"\\n=== DONE ===\")\n",
    "print(\"Total rows:\", len(df_all))\n",
    "\n",
    "# ▼ UTC → JST変換（必要なら）\n",
    "df_all[\"time\"] = pd.to_datetime(df_all[\"time\"]) + pd.Timedelta(hours=9)\n",
    "df_all.rename(columns={\"time\": \"time_jst\"}, inplace=True)\n",
    "\n",
    "df_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fa2d6ab8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1882062539.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[144]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpip install folium pandas branca\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install folium pandas branca\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "45d5f621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asami\\AppData\\Local\\Temp\\ipykernel_3540\\1044985966.py:13: FutureWarning:\n",
      "\n",
      "'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👉 完了！ブラウザにアニメーションが表示されます。\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "import pandas as pd\n",
    "import webbrowser\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# ------------------------------\n",
    "# df_all に time_jst, latitude, longitude, mag が入っている前提\n",
    "# ------------------------------\n",
    "\n",
    "# ▼ 3時間ごとに丸める\n",
    "df_all[\"time_floor\"] = df_all[\"time_jst\"].dt.floor(\"3H\")\n",
    "\n",
    "# ▼ Folium で扱える GeoJSON フォーマットに変換\n",
    "features = []\n",
    "\n",
    "for _, row in df_all.iterrows():\n",
    "    feature = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [row[\"longitude\"], row[\"latitude\"]],\n",
    "        },\n",
    "        \"properties\": {\n",
    "            \"time\": row[\"time_floor\"].strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "            \"popup\": f\"M{row['mag']}<br>{row['place']}\",\n",
    "            \"icon\": \"circle\",\n",
    "            \"iconstyle\": {\n",
    "                \"fillColor\": \"red\",\n",
    "                \"fillOpacity\": 0.6,\n",
    "                \"stroke\": \"true\",\n",
    "                \"radius\": 3 + row[\"mag\"] * 1.5,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    features.append(feature)\n",
    "\n",
    "geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": features,\n",
    "}\n",
    "\n",
    "# ▼ 地図の中心は平均値で良い\n",
    "center_lat = df_all[\"latitude\"].mean()\n",
    "center_lon = df_all[\"longitude\"].mean()\n",
    "\n",
    "# ▼ ベースマップ\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=3)\n",
    "\n",
    "# ▼ アニメーションレイヤーを追加\n",
    "TimestampedGeoJson(\n",
    "    geojson,\n",
    "    period=\"PT3H\",\n",
    "    add_last_point=True,\n",
    "    auto_play=False,\n",
    "    loop=True,\n",
    "    max_speed=1,\n",
    "    loop_button=True,\n",
    "    date_options=\"YYYY-MM-DD HH:mm\",\n",
    "    time_slider_drag_update=True,\n",
    ").add_to(m)\n",
    "\n",
    "# ▼ 保存\n",
    "html_path = \"earthquake_animation.html\"\n",
    "m.save(html_path)\n",
    "\n",
    "# ▼ ブラウザで自動オープン\n",
    "webbrowser.open(html_path)\n",
    "\n",
    "print(\"👉 完了！ブラウザにアニメーションが表示されます。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bc4d7b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asami\\AppData\\Local\\Temp\\ipykernel_3540\\4027554516.py:12: FutureWarning:\n",
      "\n",
      "'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👉 完了！3グループ色分けアニメーション地図をブラウザで開きました。\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "import pandas as pd\n",
    "import webbrowser\n",
    "import json\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# ▼ df_all が存在する前提（time_jst が datetime）\n",
    "# -------------------------------------------------------\n",
    "\n",
    "# ▼ 3時間ごとに丸める\n",
    "df_all[\"time_floor\"] = df_all[\"time_jst\"].dt.floor(\"3H\")\n",
    "\n",
    "# ▼ マグニチュードで 3 分割（quantile）\n",
    "df_all[\"group\"] = pd.qcut(df_all[\"mag\"], 3, labels=[0, 1, 2])\n",
    "\n",
    "# 色設定（3分割）\n",
    "group_colors = {\n",
    "    0: \"blue\",     # 弱い\n",
    "    1: \"yellow\",   # 中間\n",
    "    2: \"red\",      # 強い\n",
    "}\n",
    "\n",
    "# ▼ GeoJSON を構築\n",
    "features = []\n",
    "\n",
    "for _, row in df_all.iterrows():\n",
    "    color = group_colors[int(row[\"group\"])]\n",
    "    \n",
    "    feature = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [row[\"longitude\"], row[\"latitude\"]],\n",
    "        },\n",
    "        \"properties\": {\n",
    "            \"time\": row[\"time_floor\"].strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
    "            \"popup\": f\"M{row['mag']} / {row['place']}\",\n",
    "            \"icon\": \"circle\",\n",
    "            \"iconstyle\": {\n",
    "                \"fillColor\": color,\n",
    "                \"fillOpacity\": 0.7,\n",
    "                \"stroke\": \"true\",\n",
    "                \"color\": color,\n",
    "                \"radius\": 4 + row[\"mag\"] * 1.1,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    features.append(feature)\n",
    "\n",
    "geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": features,\n",
    "}\n",
    "\n",
    "# ▼ 地図中央を平均位置に\n",
    "center_lat = df_all[\"latitude\"].mean()\n",
    "center_lon = df_all[\"longitude\"].mean()\n",
    "\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=3)\n",
    "\n",
    "# ▼ アニメーションレイヤー\n",
    "TimestampedGeoJson(\n",
    "    geojson,\n",
    "    period=\"PT3H\",  \n",
    "    add_last_point=True,\n",
    "    auto_play=False,\n",
    "    loop=True,\n",
    "    max_speed=1,\n",
    "    loop_button=True,\n",
    "    date_options=\"YYYY-MM-DD HH:mm\",\n",
    "    time_slider_drag_update=True,\n",
    ").add_to(m)\n",
    "\n",
    "# ▼ 保存 & 自動オープン\n",
    "html_path = \"earthquake_color3_animation.html\"\n",
    "m.save(html_path)\n",
    "webbrowser.open(html_path)\n",
    "\n",
    "print(\"👉 完了！3グループ色分けアニメーション地図をブラウザで開きました。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3955cd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ▼ mag の NaN があれば除去\n",
    "df_all = df_all.dropna(subset=[\"mag\"]).copy()\n",
    "\n",
    "# ▼ 3分割\n",
    "df_all[\"group\"] = pd.qcut(\n",
    "    df_all[\"mag\"],\n",
    "    3,\n",
    "    labels=[0, 1, 2],\n",
    "    duplicates=\"drop\"\n",
    ")\n",
    "\n",
    "# ▼ NaN の group を除去\n",
    "df_all = df_all.dropna(subset=[\"group\"]).copy()\n",
    "\n",
    "# ▼ int に変換\n",
    "df_all[\"group\"] = df_all[\"group\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cef62066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import folium\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "import pandas as pd\n",
    "import webbrowser\n",
    "import json\n",
    "import time\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "#  ■ サンプルデータ（3時間ごと）\n",
    "#     → 本来はここにユーザーが取得した1年分のデータを入れる\n",
    "# ---------------------------------------------------------\n",
    "data = [\n",
    "    {\"lat\": 35.0, \"lon\": 135.0, \"time\": \"2025-01-01T00:00:00\"},\n",
    "    {\"lat\": 35.2, \"lon\": 135.1, \"time\": \"2025-01-01T03:00:00\"},\n",
    "    {\"lat\": 35.3, \"lon\": 135.3, \"time\": \"2025-01-01T06:00:00\"},\n",
    "    {\"lat\": 35.4, \"lon\": 135.35, \"time\": \"2025-01-01T09:00:00\"},\n",
    "    {\"lat\": 35.5, \"lon\": 135.4, \"time\": \"2025-01-01T12:00:00\"},\n",
    "    {\"lat\": 35.6, \"lon\": 135.5, \"time\": \"2025-01-01T15:00:00\"},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "#  ■ 3分割して色分け（例：緯度で 3 区画）\n",
    "# ---------------------------------------------------------\n",
    "def get_color(lat):\n",
    "    if lat < 35.25:\n",
    "        return \"rgba(255,0,0,0.4)\"      # 赤（透明）\n",
    "    elif lat < 35.45:\n",
    "        return \"rgba(0,255,0,0.4)\"      # 緑（透明）\n",
    "    else:\n",
    "        return \"rgba(0,0,255,0.4)\"      # 青（透明）\n",
    "\n",
    "df[\"color\"] = df[\"lat\"].apply(get_color)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "#  ■ GeoJSON 形式に変換（TimeDimension 用）\n",
    "#     12時間（4スライド）保持 → それ以降は自動消去\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "features = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    feature = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [row[\"lon\"], row[\"lat\"]],\n",
    "        },\n",
    "        \"properties\": {\n",
    "            \"times\": [row[\"time\"]],\n",
    "            \"style\": {\n",
    "                \"color\": row[\"color\"],\n",
    "                \"fillColor\": row[\"color\"],\n",
    "                \"fillOpacity\": 0.4,\n",
    "                \"radius\": 9\n",
    "            },\n",
    "            \"icon\": \"circle\"\n",
    "        }\n",
    "    }\n",
    "    features.append(feature)\n",
    "\n",
    "geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": features\n",
    "}\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "#  ■ 地図作成\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "m = folium.Map(location=[35.3, 135.3], zoom_start=7)\n",
    "\n",
    "TimestampedGeoJson(\n",
    "    data=geojson,\n",
    "    period=\"PT3H\",              # 3時間ステップ\n",
    "    duration=\"PT12H\",           # 12時間表示(その後消える)\n",
    "    auto_play=True,\n",
    "    loop=True,\n",
    "    add_last_point=True\n",
    ").add_to(m)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "#  ■ HTML 保存 & ブラウザで自動表示\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "html_file = \"animated_map.html\"\n",
    "m.save(html_file)\n",
    "\n",
    "# 自動でブラウザを開く\n",
    "time.sleep(0.5)\n",
    "webbrowser.open(html_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4101b605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asami\\AppData\\Local\\Temp\\ipykernel_3540\\3549422403.py:16: FutureWarning:\n",
      "\n",
      "'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import folium\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import webbrowser\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ■ 半年間の3時間ごとのデータを生成\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "start = pd.Timestamp(\"2025-01-01 00:00\")\n",
    "end   = pd.Timestamp(\"2025-06-30 21:00\")\n",
    "\n",
    "times = pd.date_range(start, end, freq=\"3H\")\n",
    "\n",
    "# サンプルとして、緯度・経度をランダム移動させたデータを生成\n",
    "# ※ 本来はここに実データを入れる\n",
    "lats = 35 + np.sin(np.linspace(0, 10, len(times))) * 0.8\n",
    "lons = 135 + np.cos(np.linspace(0, 10, len(times))) * 0.8\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"time\": times,\n",
    "    \"lat\": lats,\n",
    "    \"lon\": lons\n",
    "})\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ■ 緯度で3分割して色を付ける\n",
    "# ---------------------------------------------------------\n",
    "def get_color(lat):\n",
    "    if lat < 35.2:\n",
    "        return \"rgba(255,0,0,0.4)\"      # 赤\n",
    "    elif lat < 35.5:\n",
    "        return \"rgba(0,255,0,0.4)\"      # 緑\n",
    "    else:\n",
    "        return \"rgba(0,0,255,0.4)\"      # 青\n",
    "\n",
    "df[\"color\"] = df[\"lat\"].apply(get_color)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ■ TimeDimension 用 GeoJSON へ変換\n",
    "#    duration=\"PT12H\" → 半日で点を消す\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "features = []\n",
    "for _, row in df.iterrows():\n",
    "    feature = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [row[\"lon\"], row[\"lat\"]],\n",
    "        },\n",
    "        \"properties\": {\n",
    "            \"times\": [row[\"time\"].isoformat()],\n",
    "            \"style\": {\n",
    "                \"color\": row[\"color\"],\n",
    "                \"fillColor\": row[\"color\"],\n",
    "                \"fillOpacity\": 0.4,\n",
    "                \"radius\": 8\n",
    "            },\n",
    "            \"icon\": \"circle\"\n",
    "        }\n",
    "    }\n",
    "    features.append(feature)\n",
    "\n",
    "geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": features\n",
    "}\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ■ 地図作成（Folium）\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "m = folium.Map(location=[35.3, 135.3], zoom_start=6)\n",
    "\n",
    "TimestampedGeoJson(\n",
    "    data=geojson,\n",
    "    period=\"PT3H\",             # 3時間ごと更新\n",
    "    duration=\"PT12H\",          # 半日で透明化→消える\n",
    "    auto_play=True,\n",
    "    loop=True,\n",
    "    add_last_point=True\n",
    ").add_to(m)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ■ 保存 & ブラウザ自動起動\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "html_file = \"map_half_year.html\"\n",
    "m.save(html_file)\n",
    "\n",
    "time.sleep(0.5)\n",
    "webbrowser.open(html_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "87548c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asami\\AppData\\Local\\Temp\\ipykernel_3540\\2084161809.py:14: FutureWarning:\n",
      "\n",
      "'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import folium\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import webbrowser\n",
    "import time\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ■ 全世界の6時間ごとのデータ生成（サンプル）\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# 1年間の6時間ステップ = 365日 × 4回 = 1460点\n",
    "times = pd.date_range(\"2024-01-01\", \"2024-12-31 18:00\", freq=\"6H\")\n",
    "\n",
    "# 全世界へランダムに点をばらまく\n",
    "lats = np.random.uniform(-60, 70, len(times))   # 極地すぎると見づらいので制限\n",
    "lons = np.random.uniform(-180, 180, len(times))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"time\": times,\n",
    "    \"lat\": lats,\n",
    "    \"lon\": lons\n",
    "})\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ■ 色をランダム or 任意ルールで付与（例：緯度で色分け）\n",
    "# ---------------------------------------------------------\n",
    "def get_color(lat):\n",
    "    if lat < -20:\n",
    "        return \"rgba(0,128,255,0.5)\"   # 南半球 → 青\n",
    "    elif lat < 20:\n",
    "        return \"rgba(255,165,0,0.5)\"   # 赤道帯 → オレンジ\n",
    "    else:\n",
    "        return \"rgba(255,0,0,0.5)\"     # 北半球 → 赤\n",
    "\n",
    "df[\"color\"] = df[\"lat\"].apply(get_color)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ■ TimeDimension 用 GeoJSON 作成\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "features = []\n",
    "for _, row in df.iterrows():\n",
    "    features.append({\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [row[\"lon\"], row[\"lat\"]],\n",
    "        },\n",
    "        \"properties\": {\n",
    "            \"times\": [row[\"time\"].isoformat()],\n",
    "            \"style\": {\n",
    "                \"color\": row[\"color\"],\n",
    "                \"fillColor\": row[\"color\"],\n",
    "                \"fillOpacity\": 0.5,\n",
    "                \"radius\": 7\n",
    "            },\n",
    "            \"icon\": \"circle\"\n",
    "        }\n",
    "    })\n",
    "\n",
    "geo = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": features\n",
    "}\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ■ 地図表示（全世界）\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "m = folium.Map(\n",
    "    location=[20, 0],  # 中心はアフリカ上空あたり（世界が見やすい）\n",
    "    zoom_start=2,\n",
    "    tiles=\"cartodbpositron\"\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ■ 5秒ごとに更新するアニメーション\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "TimestampedGeoJson(\n",
    "    data=geo,\n",
    "    period=\"PT6H\",         # ← 6時間刻みデータ\n",
    "    duration=\"PT6H\",       # ← 6時間後に消える（フェードアウト効果）\n",
    "    transition_time=5000,  # ← 5秒ごとに次の時刻へ\n",
    "    auto_play=True,\n",
    "    loop=True\n",
    ").add_to(m)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ■ 保存 → 自動ブラウザオープン\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "html = \"global_6h_animation.html\"\n",
    "m.save(html)\n",
    "time.sleep(0.5)\n",
    "webbrowser.open(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9603e57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asami\\AppData\\Local\\Temp\\ipykernel_3540\\129007602.py:25: FutureWarning:\n",
      "\n",
      "'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import folium\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import webbrowser\n",
    "import time\n",
    "\n",
    "# ==========================================================\n",
    "# ■ USGS 過去 30 日の M1.0+ 地震データ取得（世界）\n",
    "# ==========================================================\n",
    "url = \"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# ==========================================================\n",
    "# ■ 必要な列を整形\n",
    "# ==========================================================\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"])        # ISO時刻\n",
    "df[\"lat\"] = df[\"latitude\"]\n",
    "df[\"lon\"] = df[\"longitude\"]\n",
    "df[\"mag\"] = df[\"mag\"].fillna(0)\n",
    "df[\"depth\"] = df[\"depth\"].fillna(0)\n",
    "\n",
    "# 6時間ごとに丸める（TimeDimension の step と揃える）\n",
    "df[\"time_6h\"] = df[\"time\"].dt.floor(\"6H\")\n",
    "\n",
    "# ==========================================================\n",
    "# ■ 深さで色を決定（浅い→赤 / 深い→青）\n",
    "# ==========================================================\n",
    "def depth_to_color(depth):\n",
    "    # depth: km\n",
    "    # 0 km → 赤, 700km → 青\n",
    "    depth_norm = min(max(depth / 700, 0), 1)\n",
    "    r = int(255 * (1 - depth_norm))\n",
    "    g = int(80 * (1 - depth_norm))\n",
    "    b = int(255 * depth_norm)\n",
    "    return f\"rgba({r},{g},{b},0.7)\"\n",
    "\n",
    "df[\"color\"] = df[\"depth\"].apply(depth_to_color)\n",
    "\n",
    "# 点サイズはマグニチュードを倍率に\n",
    "df[\"radius\"] = df[\"mag\"].clip(lower=0).apply(lambda m: 2 + m * 2)\n",
    "\n",
    "# ==========================================================\n",
    "# ■ GeoJSON の FeatureCollection 生成\n",
    "# ==========================================================\n",
    "features = []\n",
    "for _, row in df.iterrows():\n",
    "    features.append({\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [row[\"lon\"], row[\"lat\"]],\n",
    "        },\n",
    "        \"properties\": {\n",
    "            \"times\": [row[\"time_6h\"].isoformat()],\n",
    "            \"style\": {\n",
    "                \"color\": row[\"color\"],\n",
    "                \"fillColor\": row[\"color\"],\n",
    "                \"fillOpacity\": 0.7,\n",
    "                \"radius\": row[\"radius\"]\n",
    "            },\n",
    "            \"icon\": \"circle\"\n",
    "        }\n",
    "    })\n",
    "\n",
    "geo = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": features\n",
    "}\n",
    "\n",
    "# ==========================================================\n",
    "# ■ 地図を作成\n",
    "# ==========================================================\n",
    "m = folium.Map(\n",
    "    location=[20, 0],   # 全世界\n",
    "    zoom_start=2,\n",
    "    tiles=\"cartodbpositron\"\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# ■ アニメーション設定\n",
    "# ==========================================================\n",
    "TimestampedGeoJson(\n",
    "    data=geo,\n",
    "\n",
    "    period=\"PT6H\",           # 6時間刻みで表示\n",
    "    duration=\"P1M\",          # ★ 1か月経つと点が消える（Fade-out）\n",
    "    transition_time=2000,    # スライダー更新 2秒\n",
    "    auto_play=True,\n",
    "    loop=True\n",
    ").add_to(m)\n",
    "\n",
    "# ==========================================================\n",
    "# ■ 保存＆自動ブラウザ表示\n",
    "# ==========================================================\n",
    "html = \"eq_animation_month_fade.html\"\n",
    "m.save(html)\n",
    "time.sleep(0.5)\n",
    "webbrowser.open(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7cc1287b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asami\\AppData\\Local\\Temp\\ipykernel_3540\\129007602.py:25: FutureWarning:\n",
      "\n",
      "'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import folium\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import webbrowser\n",
    "import time\n",
    "\n",
    "# ==========================================================\n",
    "# ■ USGS 過去 30 日の M1.0+ 地震データ取得（世界）\n",
    "# ==========================================================\n",
    "url = \"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# ==========================================================\n",
    "# ■ 必要な列を整形\n",
    "# ==========================================================\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"])        # ISO時刻\n",
    "df[\"lat\"] = df[\"latitude\"]\n",
    "df[\"lon\"] = df[\"longitude\"]\n",
    "df[\"mag\"] = df[\"mag\"].fillna(0)\n",
    "df[\"depth\"] = df[\"depth\"].fillna(0)\n",
    "\n",
    "# 6時間ごとに丸める（TimeDimension の step と揃える）\n",
    "df[\"time_6h\"] = df[\"time\"].dt.floor(\"6H\")\n",
    "\n",
    "# ==========================================================\n",
    "# ■ 深さで色を決定（浅い→赤 / 深い→青）\n",
    "# ==========================================================\n",
    "def depth_to_color(depth):\n",
    "    # depth: km\n",
    "    # 0 km → 赤, 700km → 青\n",
    "    depth_norm = min(max(depth / 700, 0), 1)\n",
    "    r = int(255 * (1 - depth_norm))\n",
    "    g = int(80 * (1 - depth_norm))\n",
    "    b = int(255 * depth_norm)\n",
    "    return f\"rgba({r},{g},{b},0.7)\"\n",
    "\n",
    "df[\"color\"] = df[\"depth\"].apply(depth_to_color)\n",
    "\n",
    "# 点サイズはマグニチュードを倍率に\n",
    "df[\"radius\"] = df[\"mag\"].clip(lower=0).apply(lambda m: 2 + m * 2)\n",
    "\n",
    "# ==========================================================\n",
    "# ■ GeoJSON の FeatureCollection 生成\n",
    "# ==========================================================\n",
    "features = []\n",
    "for _, row in df.iterrows():\n",
    "    features.append({\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [row[\"lon\"], row[\"lat\"]],\n",
    "        },\n",
    "        \"properties\": {\n",
    "            \"times\": [row[\"time_6h\"].isoformat()],\n",
    "            \"style\": {\n",
    "                \"color\": row[\"color\"],\n",
    "                \"fillColor\": row[\"color\"],\n",
    "                \"fillOpacity\": 0.7,\n",
    "                \"radius\": row[\"radius\"]\n",
    "            },\n",
    "            \"icon\": \"circle\"\n",
    "        }\n",
    "    })\n",
    "\n",
    "geo = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": features\n",
    "}\n",
    "\n",
    "# ==========================================================\n",
    "# ■ 地図を作成\n",
    "# ==========================================================\n",
    "m = folium.Map(\n",
    "    location=[20, 0],   # 全世界\n",
    "    zoom_start=2,\n",
    "    tiles=\"cartodbpositron\"\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# ■ アニメーション設定\n",
    "# ==========================================================\n",
    "TimestampedGeoJson(\n",
    "    data=geo,\n",
    "\n",
    "    period=\"PT6H\",           # 6時間刻みで表示\n",
    "    duration=\"P1M\",          # ★ 1か月経つと点が消える（Fade-out）\n",
    "    transition_time=2000,    # スライダー更新 2秒\n",
    "    auto_play=True,\n",
    "    loop=True\n",
    ").add_to(m)\n",
    "\n",
    "# ==========================================================\n",
    "# ■ 保存＆自動ブラウザ表示\n",
    "# ==========================================================\n",
    "html = \"eq_animation_month_fade.html\"\n",
    "m.save(html)\n",
    "time.sleep(0.5)\n",
    "webbrowser.open(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64edc099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
